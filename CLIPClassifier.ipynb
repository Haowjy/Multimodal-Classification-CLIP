{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with CLIP (https://github.com/openai/CLIP)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jimmyyao/miniconda3/envs/multinews/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f7341f3f710>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imports\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RN50',\n",
       " 'RN101',\n",
       " 'RN50x4',\n",
       " 'RN50x16',\n",
       " 'RN50x64',\n",
       " 'ViT-B/32',\n",
       " 'ViT-B/16',\n",
       " 'ViT-L/14',\n",
       " 'ViT-L/14@336px']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import clip\n",
    "clip.available_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, preprocess = clip.load(\"ViT-B/32\", jit=False, device=device) # Must set jit=False for training\n",
    "del model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakedditDataset(Dataset):\n",
    "    \"\"\"Subset of fake news dataset from \"\"\"\n",
    "\n",
    "    def __init__(self, dataset, root_dir, image_preprocess=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataset (string): Path to the csv file or a pandas DF\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        if type(dataset) is str:\n",
    "            self.dataset = pd.read_csv(dataset)\n",
    "        else:\n",
    "            self.dataset = dataset\n",
    "        self.root_dir = root_dir\n",
    "        self.image_preprocess = image_preprocess\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        text = self.dataset.iloc[idx, 0]\n",
    "        img_name = os.path.join(self.root_dir, f\"{self.dataset.iloc[idx, 1]}.jpg\")\n",
    "        image = Image.open(img_name)\n",
    "        if self.image_preprocess:\n",
    "            image = self.image_preprocess(image.convert(\"RGB\"))\n",
    "            \n",
    "        label = torch.zeros(6)\n",
    "        label[self.dataset.iloc[idx, 2]] = 1\n",
    "        \n",
    "        return image, text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "trainset = FakedditDataset('train_clean.csv', 'data', image_preprocess=preprocess)\n",
    "testset = FakedditDataset('test_clean.csv', 'data', image_preprocess=preprocess)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224]) 36 torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, texts, labels = next(dataiter)\n",
    "print(images[0].shape, len(texts[0]), labels[0].shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLIPClassifier(nn.Module):\n",
    "    def __init__(self, device='cpu') -> None:\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        \n",
    "        self.clip_layer, _ = clip.load(\"ViT-B/32\", jit=True, device=device) # Changed JIT to True for just inference\n",
    "        # output of clip is 512\n",
    "        # cat image and text for 1024\n",
    "        self.fc1 = nn.Linear(1024, 512, device=device)\n",
    "        self.fc2 = nn.Linear(512, 128, device=device)\n",
    "        self.fc3 = nn.Linear(128, 6, device=device)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "    \n",
    "    def forward(self, image, text):\n",
    "        image_features = self.clip_layer.encode_image(image).float()\n",
    "        text_features = self.clip_layer.encode_text(text).float()\n",
    "        features = torch.cat((image_features, text_features), dim=1)\n",
    "\n",
    "        x = self.relu(self.fc1(features))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# classifier = CLIPClassifier(device=device)\n",
    "# classifier.device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds and y are one-hot encoded\n",
    "def binary_accuracy(preds, y):\n",
    "    preds_label = torch.argmax(preds, dim=1)\n",
    "    y_label = torch.argmax(y, dim=1)\n",
    "    \n",
    "    correct = torch.sum(preds_label==y_label).item()\n",
    "    acc = correct / len(y_label)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jimmyyao/miniconda3/envs/multinews/lib/python3.9/site-packages/clip/clip.py:159: FutureWarning: 'torch.onnx._patch_torch._node_getitem' is deprecated in version 1.13 and will be removed in version 1.14. Please Internally use '_node_get' in symbolic_helper instead..\n",
      "  if \"value\" in node.attributeNames() and str(node[\"value\"]).startswith(\"cuda\"):\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import copy\n",
    "\n",
    "# define the initial learning rate here\n",
    "learning_rate = 1e-4\n",
    "n_epochs = 50 # how many epochs to run\n",
    "momentum = 0.9\n",
    "patience = 10 # number of times to observe worsening val set error before giving up\n",
    "MODEL_LOCATION = 'models/'\n",
    "MODEL_VERSION = '2'\n",
    "FULL_LOCATION = os.path.join(MODEL_LOCATION, MODEL_VERSION)\n",
    "MODEL_PATH = os.path.join(FULL_LOCATION, f'clipclassifier.pth')\n",
    "os.makedirs(FULL_LOCATION, exist_ok=True)\n",
    "\n",
    "# define loss function and model\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "model = CLIPClassifier(device=device)\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate, momentum=momentum)\n",
    "\n",
    "trainval_lossacc = {'train_loss':[], 'train_acc':[],'valid_loss':[],'valid_acc':[]}\n",
    "\n",
    "min_val_loss = math.inf\n",
    "epoch_no_improv = 0\n",
    "\n",
    "cur_epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load from checkpoint if it exists\n",
    "# checkpoint = torch.load(MODEL_PATH, map_location=torch.device('cpu'))\n",
    "\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "# cur_epoch = checkpoint['epoch']\n",
    "# trainval_lossacc = checkpoint['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jimmyyao/miniconda3/envs/multinews/lib/python3.9/site-packages/torch/autograd/__init__.py:197: UserWarning: operator() profile_node %594 : int[] = prim::profile_ivalue(%592)\n",
      " does not have profile information (Triggered internally at ../torch/csrc/jit/codegen/cuda/graph_fuser.cpp:105.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2, Step   200] loss: 0.691\n",
      "[Epoch 2, Step   400] loss: 0.666\n",
      "[Epoch 2, Step   600] loss: 0.631\n",
      "[2] \tTrain Loss: 0.646 | Train Acc: 17.65%\n",
      "[2] \t Val. Loss: 0.550 |  Val. Acc: 30.05%\n",
      "Min val loss 0.550\n",
      "\n",
      "[Epoch 3, Step   200] loss: 0.510\n",
      "[Epoch 3, Step   400] loss: 0.443\n",
      "[Epoch 3, Step   600] loss: 0.406\n",
      "[3] \tTrain Loss: 0.441 | Train Acc: 33.32%\n",
      "[3] \t Val. Loss: 0.384 |  Val. Acc: 39.51%\n",
      "Min val loss 0.384\n",
      "\n",
      "[Epoch 4, Step   200] loss: 0.385\n",
      "[Epoch 4, Step   400] loss: 0.383\n",
      "[Epoch 4, Step   600] loss: 0.381\n",
      "[4] \tTrain Loss: 0.382 | Train Acc: 39.17%\n",
      "[4] \t Val. Loss: 0.375 |  Val. Acc: 39.52%\n",
      "Min val loss 0.375\n",
      "\n",
      "[Epoch 5, Step   200] loss: 0.378\n",
      "[Epoch 5, Step   400] loss: 0.378\n",
      "[Epoch 5, Step   600] loss: 0.380\n",
      "[5] \tTrain Loss: 0.378 | Train Acc: 39.68%\n",
      "[5] \t Val. Loss: 0.373 |  Val. Acc: 39.51%\n",
      "Min val loss 0.373\n",
      "\n",
      "[Epoch 6, Step   200] loss: 0.379\n",
      "[Epoch 6, Step   400] loss: 0.377\n",
      "[Epoch 6, Step   600] loss: 0.374\n",
      "[6] \tTrain Loss: 0.376 | Train Acc: 39.94%\n",
      "[6] \t Val. Loss: 0.370 |  Val. Acc: 39.52%\n",
      "Min val loss 0.370\n",
      "\n",
      "[Epoch 7, Step   200] loss: 0.374\n",
      "[Epoch 7, Step   400] loss: 0.374\n",
      "[Epoch 7, Step   600] loss: 0.371\n",
      "[7] \tTrain Loss: 0.373 | Train Acc: 42.67%\n",
      "[7] \t Val. Loss: 0.365 |  Val. Acc: 39.53%\n",
      "Min val loss 0.365\n",
      "\n",
      "[Epoch 8, Step   200] loss: 0.368\n",
      "[Epoch 8, Step   400] loss: 0.368\n",
      "[Epoch 8, Step   600] loss: 0.365\n",
      "[8] \tTrain Loss: 0.366 | Train Acc: 49.45%\n",
      "[8] \t Val. Loss: 0.357 |  Val. Acc: 59.82%\n",
      "Min val loss 0.357\n",
      "\n",
      "[Epoch 9, Step   200] loss: 0.363\n",
      "[Epoch 9, Step   400] loss: 0.359\n",
      "[Epoch 9, Step   600] loss: 0.351\n",
      "[9] \tTrain Loss: 0.356 | Train Acc: 57.92%\n",
      "[9] \t Val. Loss: 0.344 |  Val. Acc: 62.95%\n",
      "Min val loss 0.344\n",
      "\n",
      "[Epoch 10, Step   200] loss: 0.347\n",
      "[Epoch 10, Step   400] loss: 0.344\n",
      "[Epoch 10, Step   600] loss: 0.337\n",
      "[10] \tTrain Loss: 0.341 | Train Acc: 62.14%\n",
      "[10] \t Val. Loss: 0.328 |  Val. Acc: 63.53%\n",
      "Min val loss 0.328\n",
      "\n",
      "[Epoch 11, Step   200] loss: 0.330\n",
      "[Epoch 11, Step   400] loss: 0.327\n",
      "[Epoch 11, Step   600] loss: 0.320\n",
      "[11] \tTrain Loss: 0.324 | Train Acc: 62.68%\n",
      "[11] \t Val. Loss: 0.311 |  Val. Acc: 62.68%\n",
      "Min val loss 0.311\n",
      "\n",
      "[Epoch 12, Step   200] loss: 0.308\n",
      "[Epoch 12, Step   400] loss: 0.313\n",
      "[Epoch 12, Step   600] loss: 0.303\n",
      "[12] \tTrain Loss: 0.306 | Train Acc: 63.12%\n",
      "[12] \t Val. Loss: 0.294 |  Val. Acc: 63.59%\n",
      "Min val loss 0.294\n",
      "\n",
      "[Epoch 13, Step   200] loss: 0.294\n",
      "[Epoch 13, Step   400] loss: 0.293\n",
      "[Epoch 13, Step   600] loss: 0.292\n",
      "[13] \tTrain Loss: 0.291 | Train Acc: 64.10%\n",
      "[13] \t Val. Loss: 0.281 |  Val. Acc: 64.72%\n",
      "Min val loss 0.281\n",
      "\n",
      "[Epoch 14, Step   200] loss: 0.281\n",
      "[Epoch 14, Step   400] loss: 0.279\n",
      "[Epoch 14, Step   600] loss: 0.282\n",
      "[14] \tTrain Loss: 0.281 | Train Acc: 64.49%\n",
      "[14] \t Val. Loss: 0.280 |  Val. Acc: 63.19%\n",
      "Min val loss 0.280\n",
      "\n",
      "[Epoch 15, Step   200] loss: 0.275\n",
      "[Epoch 15, Step   400] loss: 0.272\n",
      "[Epoch 15, Step   600] loss: 0.271\n",
      "[15] \tTrain Loss: 0.271 | Train Acc: 65.22%\n",
      "[15] \t Val. Loss: 0.263 |  Val. Acc: 65.65%\n",
      "Min val loss 0.263\n",
      "\n",
      "[Epoch 16, Step   200] loss: 0.262\n",
      "[Epoch 16, Step   400] loss: 0.261\n",
      "[Epoch 16, Step   600] loss: 0.260\n",
      "[16] \tTrain Loss: 0.262 | Train Acc: 65.83%\n",
      "[16] \t Val. Loss: 0.258 |  Val. Acc: 65.79%\n",
      "Min val loss 0.258\n",
      "\n",
      "[Epoch 17, Step   200] loss: 0.249\n",
      "[Epoch 17, Step   400] loss: 0.258\n",
      "[Epoch 17, Step   600] loss: 0.257\n",
      "[17] \tTrain Loss: 0.255 | Train Acc: 66.34%\n",
      "[17] \t Val. Loss: 0.255 |  Val. Acc: 65.56%\n",
      "Min val loss 0.255\n",
      "\n",
      "[Epoch 18, Step   200] loss: 0.251\n",
      "[Epoch 18, Step   400] loss: 0.251\n",
      "[Epoch 18, Step   600] loss: 0.247\n",
      "[18] \tTrain Loss: 0.249 | Train Acc: 66.58%\n",
      "[18] \t Val. Loss: 0.248 |  Val. Acc: 66.31%\n",
      "Min val loss 0.248\n",
      "\n",
      "[Epoch 19, Step   200] loss: 0.249\n",
      "[Epoch 19, Step   400] loss: 0.240\n",
      "[Epoch 19, Step   600] loss: 0.245\n",
      "[19] \tTrain Loss: 0.244 | Train Acc: 66.77%\n",
      "[19] \t Val. Loss: 0.245 |  Val. Acc: 66.18%\n",
      "Min val loss 0.245\n",
      "\n",
      "[Epoch 20, Step   200] loss: 0.240\n",
      "[Epoch 20, Step   400] loss: 0.244\n",
      "[Epoch 20, Step   600] loss: 0.235\n",
      "[20] \tTrain Loss: 0.239 | Train Acc: 67.10%\n",
      "[20] \t Val. Loss: 0.241 |  Val. Acc: 66.25%\n",
      "Min val loss 0.241\n",
      "\n",
      "[Epoch 21, Step   200] loss: 0.231\n",
      "[Epoch 21, Step   400] loss: 0.235\n",
      "[Epoch 21, Step   600] loss: 0.233\n",
      "[21] \tTrain Loss: 0.234 | Train Acc: 67.59%\n",
      "[21] \t Val. Loss: 0.237 |  Val. Acc: 67.01%\n",
      "Min val loss 0.237\n",
      "\n",
      "[Epoch 22, Step   200] loss: 0.234\n",
      "[Epoch 22, Step   400] loss: 0.227\n",
      "[Epoch 22, Step   600] loss: 0.230\n",
      "[22] \tTrain Loss: 0.230 | Train Acc: 68.00%\n",
      "[22] \t Val. Loss: 0.244 |  Val. Acc: 66.24%\n",
      "no improvement = 1\n",
      "\n",
      "[Epoch 23, Step   200] loss: 0.221\n",
      "[Epoch 23, Step   400] loss: 0.226\n",
      "[Epoch 23, Step   600] loss: 0.224\n",
      "[23] \tTrain Loss: 0.224 | Train Acc: 68.56%\n",
      "[23] \t Val. Loss: 0.233 |  Val. Acc: 68.23%\n",
      "Min val loss 0.233\n",
      "\n",
      "[Epoch 24, Step   200] loss: 0.221\n",
      "[Epoch 24, Step   400] loss: 0.218\n",
      "[Epoch 24, Step   600] loss: 0.218\n",
      "[24] \tTrain Loss: 0.220 | Train Acc: 69.39%\n",
      "[24] \t Val. Loss: 0.229 |  Val. Acc: 68.08%\n",
      "Min val loss 0.229\n",
      "\n",
      "[Epoch 25, Step   200] loss: 0.219\n",
      "[Epoch 25, Step   400] loss: 0.216\n",
      "[Epoch 25, Step   600] loss: 0.213\n",
      "[25] \tTrain Loss: 0.215 | Train Acc: 69.96%\n",
      "[25] \t Val. Loss: 0.235 |  Val. Acc: 67.09%\n",
      "no improvement = 1\n",
      "\n",
      "[Epoch 26, Step   200] loss: 0.211\n",
      "[Epoch 26, Step   400] loss: 0.213\n",
      "[Epoch 26, Step   600] loss: 0.210\n",
      "[26] \tTrain Loss: 0.212 | Train Acc: 71.04%\n",
      "[26] \t Val. Loss: 0.231 |  Val. Acc: 68.75%\n",
      "no improvement = 2\n",
      "\n",
      "[Epoch 27, Step   200] loss: 0.208\n",
      "[Epoch 27, Step   400] loss: 0.207\n",
      "[Epoch 27, Step   600] loss: 0.202\n",
      "[27] \tTrain Loss: 0.207 | Train Acc: 72.34%\n",
      "[27] \t Val. Loss: 0.228 |  Val. Acc: 68.74%\n",
      "Min val loss 0.228\n",
      "\n",
      "[Epoch 28, Step   200] loss: 0.211\n",
      "[Epoch 28, Step   400] loss: 0.200\n",
      "[Epoch 28, Step   600] loss: 0.204\n",
      "[28] \tTrain Loss: 0.203 | Train Acc: 73.52%\n",
      "[28] \t Val. Loss: 0.223 |  Val. Acc: 71.07%\n",
      "Min val loss 0.223\n",
      "\n",
      "[Epoch 29, Step   200] loss: 0.198\n",
      "[Epoch 29, Step   400] loss: 0.195\n",
      "[Epoch 29, Step   600] loss: 0.195\n",
      "[29] \tTrain Loss: 0.197 | Train Acc: 74.82%\n",
      "[29] \t Val. Loss: 0.224 |  Val. Acc: 71.65%\n",
      "no improvement = 1\n",
      "\n",
      "[Epoch 30, Step   200] loss: 0.189\n",
      "[Epoch 30, Step   400] loss: 0.202\n",
      "[Epoch 30, Step   600] loss: 0.191\n",
      "[30] \tTrain Loss: 0.194 | Train Acc: 75.95%\n",
      "[30] \t Val. Loss: 0.217 |  Val. Acc: 72.91%\n",
      "Min val loss 0.217\n",
      "\n",
      "[Epoch 31, Step   200] loss: 0.183\n",
      "[Epoch 31, Step   400] loss: 0.187\n",
      "[Epoch 31, Step   600] loss: 0.192\n",
      "[31] \tTrain Loss: 0.188 | Train Acc: 77.18%\n",
      "[31] \t Val. Loss: 0.216 |  Val. Acc: 72.77%\n",
      "Min val loss 0.216\n",
      "\n",
      "[Epoch 32, Step   200] loss: 0.182\n",
      "[Epoch 32, Step   400] loss: 0.185\n",
      "[Epoch 32, Step   600] loss: 0.183\n",
      "[32] \tTrain Loss: 0.181 | Train Acc: 78.22%\n",
      "[32] \t Val. Loss: 0.217 |  Val. Acc: 72.31%\n",
      "no improvement = 1\n",
      "\n",
      "[Epoch 33, Step   200] loss: 0.173\n",
      "[Epoch 33, Step   400] loss: 0.170\n",
      "[Epoch 33, Step   600] loss: 0.181\n",
      "[33] \tTrain Loss: 0.175 | Train Acc: 79.22%\n",
      "[33] \t Val. Loss: 0.216 |  Val. Acc: 73.15%\n",
      "no improvement = 2\n",
      "\n",
      "[Epoch 34, Step   200] loss: 0.164\n",
      "[Epoch 34, Step   400] loss: 0.164\n",
      "[Epoch 34, Step   600] loss: 0.169\n",
      "[34] \tTrain Loss: 0.168 | Train Acc: 80.25%\n",
      "[34] \t Val. Loss: 0.216 |  Val. Acc: 72.79%\n",
      "no improvement = 3\n",
      "\n",
      "[Epoch 35, Step   200] loss: 0.166\n",
      "[Epoch 35, Step   400] loss: 0.165\n",
      "[Epoch 35, Step   600] loss: 0.161\n",
      "[35] \tTrain Loss: 0.162 | Train Acc: 80.89%\n",
      "[35] \t Val. Loss: 0.216 |  Val. Acc: 72.99%\n",
      "no improvement = 4\n",
      "\n",
      "[Epoch 36, Step   200] loss: 0.160\n",
      "[Epoch 36, Step   400] loss: 0.153\n",
      "[Epoch 36, Step   600] loss: 0.154\n",
      "[36] \tTrain Loss: 0.156 | Train Acc: 81.56%\n",
      "[36] \t Val. Loss: 0.223 |  Val. Acc: 71.43%\n",
      "no improvement = 5\n",
      "\n",
      "[Epoch 37, Step   200] loss: 0.149\n",
      "[Epoch 37, Step   400] loss: 0.150\n",
      "[Epoch 37, Step   600] loss: 0.150\n",
      "[37] \tTrain Loss: 0.150 | Train Acc: 82.17%\n",
      "[37] \t Val. Loss: 0.212 |  Val. Acc: 72.91%\n",
      "Min val loss 0.212\n",
      "\n",
      "[Epoch 38, Step   200] loss: 0.150\n",
      "[Epoch 38, Step   400] loss: 0.142\n",
      "[Epoch 38, Step   600] loss: 0.144\n",
      "[38] \tTrain Loss: 0.145 | Train Acc: 82.81%\n",
      "[38] \t Val. Loss: 0.216 |  Val. Acc: 73.67%\n",
      "no improvement = 1\n",
      "\n",
      "[Epoch 39, Step   200] loss: 0.134\n",
      "[Epoch 39, Step   400] loss: 0.147\n",
      "[Epoch 39, Step   600] loss: 0.137\n",
      "[39] \tTrain Loss: 0.140 | Train Acc: 83.04%\n",
      "[39] \t Val. Loss: 0.212 |  Val. Acc: 73.60%\n",
      "no improvement = 2\n",
      "\n",
      "[Epoch 40, Step   200] loss: 0.130\n",
      "[Epoch 40, Step   400] loss: 0.131\n",
      "[Epoch 40, Step   600] loss: 0.132\n",
      "[40] \tTrain Loss: 0.130 | Train Acc: 84.00%\n",
      "[40] \t Val. Loss: 0.216 |  Val. Acc: 73.22%\n",
      "no improvement = 3\n",
      "\n",
      "[Epoch 41, Step   200] loss: 0.120\n",
      "[Epoch 41, Step   400] loss: 0.123\n",
      "[Epoch 41, Step   600] loss: 0.126\n",
      "[41] \tTrain Loss: 0.124 | Train Acc: 84.48%\n",
      "[41] \t Val. Loss: 0.238 |  Val. Acc: 72.57%\n",
      "no improvement = 4\n",
      "\n",
      "[Epoch 42, Step   200] loss: 0.119\n",
      "[Epoch 42, Step   400] loss: 0.128\n",
      "[Epoch 42, Step   600] loss: 0.124\n",
      "[42] \tTrain Loss: 0.123 | Train Acc: 84.44%\n",
      "[42] \t Val. Loss: 0.214 |  Val. Acc: 73.26%\n",
      "no improvement = 5\n",
      "\n",
      "[Epoch 43, Step   200] loss: 0.113\n",
      "[Epoch 43, Step   400] loss: 0.111\n",
      "[Epoch 43, Step   600] loss: 0.118\n",
      "[43] \tTrain Loss: 0.112 | Train Acc: 85.75%\n",
      "[43] \t Val. Loss: 0.218 |  Val. Acc: 73.69%\n",
      "no improvement = 6\n",
      "\n",
      "[Epoch 44, Step   200] loss: 0.106\n",
      "[Epoch 44, Step   400] loss: 0.102\n",
      "[Epoch 44, Step   600] loss: 0.109\n",
      "[44] \tTrain Loss: 0.107 | Train Acc: 86.27%\n",
      "[44] \t Val. Loss: 0.233 |  Val. Acc: 72.47%\n",
      "no improvement = 7\n",
      "\n",
      "[Epoch 45, Step   200] loss: 0.112\n",
      "[Epoch 45, Step   400] loss: 0.111\n",
      "[Epoch 45, Step   600] loss: 0.099\n",
      "[45] \tTrain Loss: 0.107 | Train Acc: 86.43%\n",
      "[45] \t Val. Loss: 0.224 |  Val. Acc: 74.14%\n",
      "no improvement = 8\n",
      "\n",
      "[Epoch 46, Step   200] loss: 0.101\n",
      "[Epoch 46, Step   400] loss: 0.098\n",
      "[Epoch 46, Step   600] loss: 0.096\n",
      "[46] \tTrain Loss: 0.099 | Train Acc: 87.43%\n",
      "[46] \t Val. Loss: 0.239 |  Val. Acc: 71.80%\n",
      "no improvement = 9\n",
      "\n",
      "[Epoch 47, Step   200] loss: 0.098\n",
      "[Epoch 47, Step   400] loss: 0.091\n",
      "[Epoch 47, Step   600] loss: 0.092\n",
      "[47] \tTrain Loss: 0.094 | Train Acc: 88.20%\n",
      "[47] \t Val. Loss: 0.233 |  Val. Acc: 73.62%\n",
      "Early Stopping\n",
      "no improvement = 10\n",
      "\n",
      "[Epoch 48, Step   200] loss: 0.090\n",
      "[Epoch 48, Step   400] loss: 0.099\n",
      "[Epoch 48, Step   600] loss: 0.095\n",
      "[48] \tTrain Loss: 0.095 | Train Acc: 88.37%\n",
      "[48] \t Val. Loss: 0.231 |  Val. Acc: 73.82%\n",
      "Early Stopping\n",
      "no improvement = 11\n",
      "\n",
      "[Epoch 49, Step   200] loss: 0.090\n",
      "[Epoch 49, Step   400] loss: 0.088\n",
      "[Epoch 49, Step   600] loss: 0.088\n",
      "[49] \tTrain Loss: 0.089 | Train Acc: 89.16%\n",
      "[49] \t Val. Loss: 0.233 |  Val. Acc: 74.56%\n",
      "Early Stopping\n",
      "no improvement = 12\n",
      "\n",
      "[Epoch 50, Step   200] loss: 0.084\n",
      "[Epoch 50, Step   400] loss: 0.085\n",
      "[Epoch 50, Step   600] loss: 0.083\n",
      "[50] \tTrain Loss: 0.085 | Train Acc: 89.96%\n",
      "[50] \t Val. Loss: 0.229 |  Val. Acc: 75.04%\n",
      "Early Stopping\n",
      "no improvement = 13\n",
      "\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(cur_epoch,n_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    # Training\n",
    "    epoch_loss = 0.0\n",
    "    epoch_acc = 0.0\n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        images, texts, labels = data\n",
    "        \n",
    "        image_input = torch.tensor(np.stack(images)).to(device)\n",
    "        text_tokens = clip.tokenize(texts, truncate=True).to(device) # truncate: some titles are longer than 77, but I think there is more than enough context in 77 words\n",
    "        labels = labels.float().to(device)\n",
    "\n",
    "        # zero parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward\n",
    "        output = model(image_input, text_tokens)\n",
    "\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += binary_accuracy(output, labels)\n",
    "        if i % 200 == 199:  # print every 200 mini-batches\n",
    "            print('[Epoch %d, Step %5d] loss: %.3f' %\n",
    "                  (epoch, i + 1, running_loss / 200))\n",
    "            running_loss = 0.0\n",
    "    train_loss, train_acc = epoch_loss / len(trainloader), epoch_acc / len(trainloader)\n",
    "\n",
    "    trainval_lossacc['train_loss'].append(train_loss)\n",
    "    trainval_lossacc['train_acc'].append(train_acc)\n",
    "\n",
    "    # Evaluate with Test dataset\n",
    "    epoch_loss = 0.0\n",
    "    epoch_acc = 0.0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(testloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            images, texts, labels = data\n",
    "            image_input = torch.tensor(np.stack(images)).to(device)\n",
    "            # print(image_input.shape, image_input.dtype)\n",
    "            text_tokens = clip.tokenize(texts, truncate=True).to(device) # truncate: some titles are longer than 77, but I think there is more than enough context in 77 words\n",
    "            # print(text_tokens.shape, text_tokens.dtype)\n",
    "            labels = labels.float().to(device)\n",
    "            # Forward \n",
    "            output = model(image_input, text_tokens)\n",
    "            \n",
    "            # Compute the loss using the final output\n",
    "            loss = criterion(output, labels)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += binary_accuracy(output, labels)\n",
    "    \n",
    "    valid_loss, valid_acc = epoch_loss / len(testloader), epoch_acc / len(testloader)\n",
    "\n",
    "    trainval_lossacc['valid_loss'].append(valid_loss)\n",
    "    trainval_lossacc['valid_acc'].append(valid_acc)\n",
    "    # Showing statistics\n",
    "    print(f'[{epoch}] \\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'[{epoch}] \\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "\n",
    "    # Early stopping condition\n",
    "    # https://stackoverflow.com/questions/60200088/how-to-make-early-stopping-in-image-classification-pytorch\n",
    "    if valid_loss < min_val_loss:\n",
    "        min_val_loss = valid_loss\n",
    "        epoch_no_improv = 0\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': trainval_lossacc,\n",
    "            }, MODEL_PATH)\n",
    "        \n",
    "        print(f'Min val loss {min_val_loss:.3f}')\n",
    "    else:\n",
    "        epoch_no_improv += 1\n",
    "        if epoch_no_improv >= patience:\n",
    "            print('Early Stopping')\n",
    "            break\n",
    "            # os.makedirs(f'drive/Shareddrives/MultimodalNews/models/{MODEL_VERSION}/', exist_ok=True)\n",
    "            # torch.save(best_model, f\"drive/Shareddrives/MultimodalNews/models/{MODEL_VERSION}/clipclassifier.pth\")\n",
    "        print(f\"no improvement = {epoch_no_improv}\")\n",
    "    print()\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Final Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load from checkpoint if it exists\n",
    "checkpoint = torch.load(MODEL_PATH, map_location=torch.device('cpu'))\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "cur_epoch = checkpoint['epoch']\n",
    "trainval_lossacc = checkpoint['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final train loss: 0.14999\n",
      "final train acc: 0.82174\n",
      "\n",
      "final valid loss: 0.21184\n",
      "final valid acc: 0.72906\n"
     ]
    }
   ],
   "source": [
    "print(f\"final train loss: {trainval_lossacc['train_loss'][-1]:.5f}\")\n",
    "print(f\"final train acc: {trainval_lossacc['train_acc'][-1]:.5f}\")\n",
    "print()\n",
    "print(f\"final valid loss: {trainval_lossacc['valid_loss'][-1]:.5f}\")\n",
    "print(f\"final valid acc: {trainval_lossacc['valid_acc'][-1]:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36] \tTrain Loss: 0.14999 | Train Acc: 82.17381%\n",
      "[36] \t Val. Loss: 0.21184 |  Val. Acc: 72.90648%\n"
     ]
    }
   ],
   "source": [
    "print(f\"[{cur_epoch}] \\tTrain Loss: {trainval_lossacc['train_loss'][-1]:.5f} | Train Acc: {trainval_lossacc['train_acc'][-1]*100:.5f}%\")\n",
    "print(f\"[{cur_epoch}] \\t Val. Loss: {trainval_lossacc['valid_loss'][-1]:.5f} |  Val. Acc: {trainval_lossacc['valid_acc'][-1]*100:.5f}%\")\n",
    "# [36] \tTrain Loss: 0.14999 | Train Acc: 82.17381%\n",
    "# [36] \t Val. Loss: 0.21184 |  Val. Acc: 72.90648%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multinews",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "12a1584764fc80bec723ae766c7274bc1045a0de66e94735d00d14d294f6d446"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
