{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "add2be6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "#import numpy as np\n",
    "# nlp library of Pytorch\n",
    "from torchtext import data\n",
    "#from torchtext.legacy import data\n",
    "#from torchtext.legacy import data\n",
    "#from torchtext.legacy import datasets\n",
    "\n",
    "import warnings as wrn\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor, ToPILImage\n",
    "from torchvision import transforms, utils\n",
    "import numpy as np\n",
    "import random\n",
    "import torchvision\n",
    "\n",
    "import tarfile\n",
    "import io\n",
    "import os\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "wrn.filterwarnings('ignore')\n",
    "SEED = 2021\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cuda.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61208756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23982 entries, 0 to 23981\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   clean_title  23982 non-null  object\n",
      " 1   id           23982 non-null  object\n",
      " 2   label        23982 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 562.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data_ = pd.read_csv('./csv/train.csv')\n",
    "data_.head()\n",
    "data_.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e7f8b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Field is a normal column \n",
    "# LabelField is the label column.\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "def tokenizer(text): # create a tokenizer function\n",
    "    return [tok.text for tok in nlp.tokenizer(text)]\n",
    "\n",
    "TEXT = data.Field(tokenize=tokenizer,batch_first=True,include_lengths=True)\n",
    "ID = data.Field(dtype = torch.float,batch_first=True)\n",
    "LABEL = data.LabelField(dtype = torch.float,batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "346aec3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [('clean_title',TEXT), ('id', ID), ('label',LABEL)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b55ad72",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = data.TabularDataset(path=\"./csv/train.csv\",\n",
    "                                    format=\"csv\",\n",
    "                                    fields=fields,\n",
    "                                    skip_header=True\n",
    "                                   )\n",
    "\n",
    "test_data = data.TabularDataset(path=\"./csv/validate.csv\",\n",
    "                                    format=\"csv\",\n",
    "                                    fields=fields,\n",
    "                                    skip_header=True\n",
    "                                   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cba77ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# train and validation splitting\n",
    "train_data,valid_data = training_data.split(split_ratio=0.5,\n",
    "                                            random_state=random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e63aef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(training_data,test_data)\n",
    "ID.build_vocab(training_data,test_data)\n",
    "LABEL.build_vocab(training_data,test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2845b5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of text vocab: 26847\n",
      "Size of label vocab: 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('the', 9337),\n",
       " ('a', 6954),\n",
       " ('of', 4911),\n",
       " ('in', 4622),\n",
       " ('to', 4528),\n",
       " ('this', 4335),\n",
       " ('my', 2527),\n",
       " ('i', 2514),\n",
       " ('on', 2422),\n",
       " ('and', 2291)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Size of text vocab:\",len(TEXT.vocab))\n",
    "print(\"Size of label vocab:\",len(LABEL.vocab))\n",
    "TEXT.vocab.freqs.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3229c3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "train_iterator,validation_iterator = data.BucketIterator.splits(\n",
    "    (train_data,valid_data),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    # Sort key is how to sort the samples\n",
    "    sort_key = lambda x:len(x.clean_title),\n",
    "    sort_within_batch = True,\n",
    "    device = device\n",
    ")\n",
    "\n",
    "test_iterator = data.BucketIterator(\n",
    "    dataset = test_data,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    train = False,\n",
    "    sort_key = False,\n",
    "    sort = False,\n",
    "    sort_within_batch = False,\n",
    "    device = device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82aa7f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clean_title': ['new', 'image', 'from', 'the', 'mandalorian'], 'id': ['d0bzlq'], 'label': '0'}\n"
     ]
    }
   ],
   "source": [
    "print(vars(test_iterator.data()[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96742746",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self,vocab_size):\n",
    "        super(Net,self).__init__()\n",
    "        #lstm part\n",
    "        self.vocab_size = vocab_size\n",
    "        self.word_embed = nn.Embedding(vocab_size, 100)\n",
    "        self.layer = nn.LSTM(input_size=100, hidden_size=64, num_layers = 2, batch_first=True, bidirectional=False)\n",
    "        \n",
    "        #combine part\n",
    "        self.drop = nn.Dropout(p=0.3)\n",
    "        self.label1 = nn.Linear(64,64)\n",
    "        self.acti1 = nn.ReLU()\n",
    "        self.label2 = nn.Linear(64,64)\n",
    "        self.acti2 = nn.ReLU()\n",
    "        self.label3 = nn.Linear(64,6)\n",
    "        self.acti3 = nn.Sigmoid()\n",
    "        #self.label6 = nn.Linear(6,6)\n",
    "        \n",
    "    def forward(self, text, text_length):\n",
    "        #lstm part\n",
    "        embed = self.word_embed(text)\n",
    "        #print(embed.shape)\n",
    "        out, _ = self.layer(embed)\n",
    "        outs = out[range(len(out)), text_length - 1, :64]\n",
    "        #print(outs.shape)\n",
    "        \n",
    "        #cnn part\n",
    "        #x = self.layer1(image)\n",
    "        #x = self.acti1(x)\n",
    "        #x = self.pool1(x)\n",
    "        #x = self.layer2(x)\n",
    "        #x = self.acti1(x)\n",
    "        #x = self.flat(x)\n",
    "        #print(x.size())\n",
    "        #x = self.layer3(x)\n",
    "        #output_cnn = self.acti3(x)\n",
    "        \n",
    "        #combined = torch.cat((outs,output_cnn), 1)\n",
    "        \n",
    "        #print(outs.shape)\n",
    "        tag = self.label1(outs)\n",
    "        tag_score = self.acti1(tag)\n",
    "        #tag_score = self.drop(tag_score)\n",
    "        #tag_score = self.label2(tag_score)\n",
    "        #tag_score = self.acti2(tag_score)\n",
    "        #tag_score = self.drop(tag_score)\n",
    "        tag_score = self.label3(tag_score)\n",
    "        tag_score = self.acti3(tag_score)\n",
    "        #print(tag_score.shape)\n",
    "        #result = torch.argmax(tag_score,dim=1,keepdim=True)\n",
    "        #result = self.label6(tag_score)\n",
    "        return tag_score\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7e3cb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(len(TEXT.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12708cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "model = model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(),lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b07561b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def active_label(tensor):\n",
    "    vec = []\n",
    "    for i in range(1):\n",
    "        if tensor[i] == 0:\n",
    "            vec = [1,0,0,0,0,0]\n",
    "        elif tensor[i] == 1:\n",
    "            vec = [0,1,0,0,0,0]\n",
    "        elif tensor[i] == 2:\n",
    "            vec = [0,0,1,0,0,0]\n",
    "        elif tensor[i] == 3:\n",
    "            vec = [0,0,0,1,0,0]\n",
    "        elif tensor[i] == 4:\n",
    "            vec = [0,0,0,0,1,0]\n",
    "        elif tensor[i] == 5:\n",
    "            vec = [0,0,0,0,0,1]\n",
    "    return  torch.tensor(vec, dtype=torch.float, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fe9fe5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predict, target):\n",
    "    correct = 0\n",
    "    #print(predict)\n",
    "    actual = torch.argmax(predict,dim=0,keepdim=True).squeeze()\n",
    "    #print(actual.item())\n",
    "    for i in range(1):\n",
    "        if actual.item() == target.item():\n",
    "            correct += 1\n",
    "    \n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20cb0175",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torchtext \n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "def train(model,iterator,optimizer,criterion):\n",
    "    directory = \"./data/\" \n",
    "    \n",
    "    epoch_loss = 0.0\n",
    "    epoch_acc = 0.0\n",
    "    idlist = ID.vocab.itos\n",
    "    model.train()\n",
    "    i = 1\n",
    "    #print(\"gets there\")\n",
    "    for batch in iterator:\n",
    "        #print(\"gets here\")\n",
    "        # cleaning the cache of optimizer\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #keep track of process\n",
    "        if i % 5000 == 0:\n",
    "            print(i)\n",
    "        i += 1\n",
    "        \n",
    "        text,text_lengths = batch.clean_title\n",
    "        \n",
    "        #modified\n",
    "\n",
    "        if(text.shape[0] == 1):\n",
    "            # forward propagation and squeezing\n",
    "            predictions = model(text,text_lengths).squeeze()\n",
    "            #print(predictions)\n",
    "            #print(batch.country)\n",
    "            target = active_label(batch.label)\n",
    "            #print(target)\n",
    "            #print(torch.unsqueeze(batch.country,1).type())\n",
    "            # computing loss / backward propagation\n",
    "            loss = criterion(predictions,target)\n",
    "            #loss = Variable(loss, requires_grad = True)\n",
    "            loss.backward()\n",
    "\n",
    "            # accuracy\n",
    "            acc = accuracy(predictions,batch.label)\n",
    "            # updating params\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc\n",
    "    # It'll return the means of loss and accuracy\n",
    "    return epoch_loss / (len(iterator)), epoch_acc / (len(iterator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4fa7243c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,iterator,criterion):\n",
    "    directory = \"./data/\" \n",
    "    \n",
    "    epoch_loss = 0.0\n",
    "    epoch_acc = 0.0\n",
    "    idlist = ID.vocab.itos\n",
    "    model.eval()\n",
    "    \n",
    "    pred = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        i = 1\n",
    "        #print(\"gets there\")\n",
    "        for batch in iterator:\n",
    "            #keep track of process\n",
    "            if i % 5000 == 0:\n",
    "                print(i)\n",
    "            i += 1\n",
    "\n",
    "            text,text_lengths = batch.clean_title\n",
    "           \n",
    "            #print(x.shape)\n",
    "            #print(ids.shape)\n",
    "            #modified\n",
    "\n",
    "            if(text.shape[0] == 1):\n",
    "                # forward propagation and squeezing\n",
    "                predictions = model(text,text_lengths).squeeze()\n",
    "                #print(predictions)\n",
    "                #print(batch.country)\n",
    "                target = active_label(batch.label)\n",
    "                #print(target)\n",
    "                #print(torch.unsqueeze(batch.country,1).type())\n",
    "                # computing loss / backward propagation\n",
    "                loss = criterion(predictions,target)\n",
    "                # accuracy\n",
    "                acc = accuracy(predictions,batch.label)\n",
    "                \n",
    "                pred += [torch.argmax(predictions,dim=0,keepdim=True).squeeze()]\n",
    "                \n",
    "                epoch_loss += loss.item()\n",
    "                epoch_acc += acc\n",
    "    # It'll return the means of loss and accuracy\n",
    "    return epoch_loss / (len(iterator)), epoch_acc / (len(iterator)), pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8255ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "5000\n",
      "10000\n",
      "5000\n",
      "10000\n",
      "\tTrain Loss: 1.448 | Train Acc: 56.35%\n",
      "\t Val. Loss: 1.446 |  Val. Acc: 56.00%\n",
      "\n",
      "2\n",
      "5000\n",
      "10000\n",
      "5000\n",
      "10000\n",
      "\tTrain Loss: 1.406 | Train Acc: 59.06%\n",
      "\t Val. Loss: 1.410 |  Val. Acc: 58.96%\n",
      "\n",
      "3\n",
      "5000\n",
      "10000\n",
      "5000\n",
      "10000\n",
      "\tTrain Loss: 1.372 | Train Acc: 62.20%\n",
      "\t Val. Loss: 1.414 |  Val. Acc: 58.68%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCH_NUMBER = 3\n",
    "for epoch in range(1,EPOCH_NUMBER+1):\n",
    "    print(epoch)\n",
    "    \n",
    "    train_loss,train_acc = train(model,train_iterator,optimizer,criterion)\n",
    "    \n",
    "    valid_loss,valid_acc,_ = evaluate(model,validation_iterator,criterion)\n",
    "    \n",
    "    # Showing statistics\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d19061f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "\t Val. Loss: 1.414 |  Val. Acc: 59.11%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss,test_acc,pred = evaluate(model,test_iterator,criterion)\n",
    "    \n",
    "# Showing statistics\n",
    "print(f'\\t Val. Loss: {test_loss:.3f} |  Val. Acc: {test_acc*100:.2f}%')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd2ff4d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7995"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "334e8180",
   "metadata": {},
   "outputs": [],
   "source": [
    "predics = []\n",
    "for i in range(len(pred)):\n",
    "    predics += [pred[i].item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77d63717",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.read_csv('./csv/test_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a61d9562",
   "metadata": {},
   "outputs": [],
   "source": [
    "output[\"Text_Basline\"] = predics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "434dac00",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv('./csv/test_clean_n.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70581518",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multinews",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 14:31:59) \n[GCC 11.2.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "12a1584764fc80bec723ae766c7274bc1045a0de66e94735d00d14d294f6d446"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
